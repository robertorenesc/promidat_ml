{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos Calibración de Modelos\n",
    "\n",
    "## Tarea 1\n",
    "\n",
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
      "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
      "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
      "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
      "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
      "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
      "...        ...       ...       ...       ...       ...       ...        ...   \n",
      "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
      "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
      "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
      "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
      "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
      "\n",
      "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
      "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
      "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
      "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
      "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
      "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
      "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
      "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
      "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
      "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
      "\n",
      "        maxfun   meandom    mindom    maxdom   dfrange   modindx     genero  \n",
      "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  Masculino  \n",
      "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  Masculino  \n",
      "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  Masculino  \n",
      "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  Masculino  \n",
      "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  Masculino  \n",
      "...        ...       ...       ...       ...       ...       ...        ...  \n",
      "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929   Femenino  \n",
      "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897   Femenino  \n",
      "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759   Femenino  \n",
      "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002   Femenino  \n",
      "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000   Femenino  \n",
      "\n",
      "[3168 rows x 21 columns]\n",
      "\n",
      "Variables Predictoras:\n",
      "\n",
      "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
      "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
      "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
      "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
      "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
      "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
      "\n",
      "          kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
      "0   274.402906  0.893369  0.491918  0.000000  0.059781  0.084279  0.015702   \n",
      "1   634.613855  0.892193  0.513724  0.000000  0.066009  0.107937  0.015826   \n",
      "2  1024.927705  0.846389  0.478905  0.000000  0.077316  0.098706  0.015656   \n",
      "3     4.177296  0.963322  0.727232  0.083878  0.151228  0.088965  0.017798   \n",
      "4     4.333713  0.971955  0.783568  0.104261  0.135120  0.106398  0.016931   \n",
      "\n",
      "     maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
      "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  \n",
      "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  \n",
      "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  \n",
      "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  \n",
      "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  \n",
      "\n",
      "Variable a Predecir:\n",
      "\n",
      "      genero\n",
      "0  Masculino\n",
      "1  Masculino\n",
      "2  Masculino\n",
      "3  Masculino\n",
      "4  Masculino\n",
      "\n",
      "Precisión Global: 0.7301775147928994\n",
      "\n",
      "Precisión por Categoría:\n",
      "\n",
      "   Femenino  Masculino\n",
      "0   0.52673   0.935075\n",
      "Matriz de Comparación\n",
      "                          K-Neighbors  Random Forest  ADA Boosting  \\\n",
      "Precisión Global             0.712934       0.982650      0.971609   \n",
      "Error Global                 0.287066       0.017350      0.028391   \n",
      "Precisión Femenino           0.664452       0.980066      0.953488   \n",
      "Precisión Masculino          0.756757       0.984985      0.987988   \n",
      "Falso Positivo Femenino      0.335548       0.019934      0.046512   \n",
      "Falso Positivo Masculino     0.243243       0.015015      0.012012   \n",
      "Asertividad Femenino         0.335548       0.019934      0.046512   \n",
      "Asertividad Masculino        0.243243       0.015015      0.012012   \n",
      "\n",
      "                          XG Boosting  SVM Model  Decision Tree  \\\n",
      "Precisión Global             0.973186   0.679811       0.960568   \n",
      "Error Global                 0.026814   0.320189       0.039432   \n",
      "Precisión Femenino           0.963455   0.568106       0.956811   \n",
      "Precisión Masculino          0.981982   0.780781       0.963964   \n",
      "Falso Positivo Femenino      0.036545   0.431894       0.043189   \n",
      "Falso Positivo Masculino     0.018018   0.219219       0.036036   \n",
      "Asertividad Femenino         0.036545   0.431894       0.043189   \n",
      "Asertividad Masculino        0.018018   0.219219       0.036036   \n",
      "\n",
      "                          Multi Layer Perceptron  \n",
      "Precisión Global                        0.730178  \n",
      "Error Global                            0.269822  \n",
      "Precisión Femenino                      0.526730  \n",
      "Precisión Masculino                     0.935075  \n",
      "Falso Positivo Femenino                 0.473270  \n",
      "Falso Positivo Masculino                0.064925  \n",
      "Asertividad Femenino                    0.473270  \n",
      "Asertividad Masculino                   0.064925  \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "20/20 [==============================] - 0s 774us/step - loss: 0.0954 - accuracy: 0.9669\n",
      "\n",
      "Precisión Global: 0.9668769716088328\n",
      "\n",
      "Precisión por Categoría:\n",
      "\n",
      "   Femenino  Masculino\n",
      "0  0.987988   0.943522\n",
      "                          K-Neighbors  Random Forest  ADA Boosting  \\\n",
      "Precisión Global             0.712934       0.982650      0.971609   \n",
      "Error Global                 0.287066       0.017350      0.028391   \n",
      "Precisión Femenino           0.664452       0.980066      0.953488   \n",
      "Precisión Masculino          0.756757       0.984985      0.987988   \n",
      "Falso Positivo Femenino      0.335548       0.019934      0.046512   \n",
      "Falso Positivo Masculino     0.243243       0.015015      0.012012   \n",
      "Asertividad Femenino         0.335548       0.019934      0.046512   \n",
      "Asertividad Masculino        0.243243       0.015015      0.012012   \n",
      "\n",
      "                          XG Boosting  SVM Model  Decision Tree  \\\n",
      "Precisión Global             0.973186   0.679811       0.960568   \n",
      "Error Global                 0.026814   0.320189       0.039432   \n",
      "Precisión Femenino           0.963455   0.568106       0.956811   \n",
      "Precisión Masculino          0.981982   0.780781       0.963964   \n",
      "Falso Positivo Femenino      0.036545   0.431894       0.043189   \n",
      "Falso Positivo Masculino     0.018018   0.219219       0.036036   \n",
      "Asertividad Femenino         0.036545   0.431894       0.043189   \n",
      "Asertividad Masculino        0.018018   0.219219       0.036036   \n",
      "\n",
      "                          Multi Layer Perceptron  Tensorflow/Keras  \n",
      "Precisión Global                        0.730178          0.966877  \n",
      "Error Global                            0.269822          0.033123  \n",
      "Precisión Femenino                      0.526730          0.987988  \n",
      "Precisión Masculino                     0.935075          0.943522  \n",
      "Falso Positivo Femenino                 0.473270          0.012012  \n",
      "Falso Positivo Masculino                0.064925          0.056478  \n",
      "Asertividad Femenino                    0.473270          0.012012  \n",
      "Asertividad Masculino                   0.064925          0.056478  \n"
     ]
    }
   ],
   "source": [
    "from utils.DataFrameUtils import DataFrameUtils\n",
    "from methodology.supervised.classificators.MLPerceptronModel import MLPerceptronModel\n",
    "from methodology.supervised.classificators.KNeighborsModel import KNeighborsModel\n",
    "from methodology.supervised.classificators.ADABoostingModel import ADABoostingModel\n",
    "from methodology.supervised.classificators.XGBoostingModel import XGBoostingModel\n",
    "from methodology.supervised.classificators.RandomForestModel import RandomForestModel\n",
    "from methodology.supervised.classificators.SVMModel import SVMModel\n",
    "from methodology.supervised.classificators.DecisionTreeModel import DecisionTreeModel\n",
    "from methodology.supervised.classificators.KerasModel import KerasModel\n",
    "\n",
    "# 1. \n",
    "voces_path = \"/Users/rsalazar/Development/learning/machine_learning/promidat/src/data/voces.csv\"\n",
    "data_voces = DataFrameUtils.read_cvs(voces_path, delimiter=\",\", decimal=\".\", index_col=None)\n",
    "print(data_voces)\n",
    "\n",
    "# 2.\n",
    "mlpModel = MLPerceptronModel(data_voces)\n",
    "mlpModel.build_model(variable_predict=\"genero\", train_size=0.2)\n",
    "mlpModel.print_testing_info()\n",
    "\n",
    "# 3.\n",
    "mlpModel.train_model(metadata = {\"hidden_layer_sizes\": (1000,500)})\n",
    "\n",
    "# 4.\n",
    "mlpModel.print_indexes_info()\n",
    "\n",
    "# 5.1. Generación de los modelos anteriores\n",
    "# K-Neighbors\n",
    "kNeighborsModel = KNeighborsModel(data_voces)\n",
    "kNeighborsModel.build_model(variable_predict = \"genero\", train_size = 0.8)\n",
    "kNeighborsModel.train_model(metadata = {})\n",
    "kNeighborsModel.calculate_indexes()\n",
    "\n",
    "# Random Forest\n",
    "randomForestModel = RandomForestModel(data_voces)\n",
    "randomForestModel.build_model(variable_predict = \"genero\", train_size = 0.8)\n",
    "randomForestModel.train_model(metadata = {})\n",
    "randomForestModel.calculate_indexes()\n",
    "\n",
    "# ADA Boosting\n",
    "adaBoostingModel = ADABoostingModel(data_voces)\n",
    "adaBoostingModel.build_model(variable_predict = \"genero\", train_size = 0.8)\n",
    "adaBoostingModel.train_model(metadata = {})\n",
    "adaBoostingModel.calculate_indexes()\n",
    "\n",
    "# ADA Boosting\n",
    "xgBoostingModel = XGBoostingModel(data_voces)\n",
    "xgBoostingModel.build_model(variable_predict = \"genero\", train_size = 0.8)\n",
    "xgBoostingModel.train_model(metadata = {})\n",
    "xgBoostingModel.calculate_indexes()\n",
    "\n",
    "# Decision Tree\n",
    "decisionTreeModel = DecisionTreeModel(data_voces)\n",
    "decisionTreeModel.build_model(variable_predict = \"genero\", train_size = 0.8)\n",
    "decisionTreeModel.train_model(metadata = {})\n",
    "decisionTreeModel.calculate_indexes()\n",
    "\n",
    "# Support Vector Machines\n",
    "svmModel = SVMModel(data_voces)\n",
    "svmModel.build_model(variable_predict = \"genero\", train_size = 0.8)\n",
    "svmModel.train_model(metadata = {})\n",
    "svmModel.calculate_indexes()\n",
    "\n",
    "# 5.2 Generación de cuadro comparativo\n",
    "print(\"Matriz de Comparación\")\n",
    "indexes = DataFrameUtils.create_dataframe_from_dict(\n",
    "    [\n",
    "        kNeighborsModel.indexes.get_indexes_dictionary(),\n",
    "        randomForestModel.indexes.get_indexes_dictionary(),\n",
    "        adaBoostingModel.indexes.get_indexes_dictionary(),\n",
    "        xgBoostingModel.indexes.get_indexes_dictionary(),\n",
    "        svmModel.indexes.get_indexes_dictionary(),\n",
    "        decisionTreeModel.indexes.get_indexes_dictionary(),\n",
    "        mlpModel.indexes.get_indexes_dictionary()\n",
    "    ], columns = [\n",
    "        \"K-Neighbors\",\n",
    "        \"Random Forest\", \n",
    "        \"ADA Boosting\", \n",
    "        \"XG Boosting\",\n",
    "        \"SVM Model\",\n",
    "        \"Decision Tree\",\n",
    "        \"Multi Layer Perceptron\"])\n",
    "print(indexes)\n",
    "\n",
    "# 6. Generación con Tensorflow/Keras\n",
    "\n",
    "kerasModel = KerasModel(data_voces)\n",
    "kerasModel.build_model(variable_predict = \"genero\", train_size = 0.8)\n",
    "kerasModel.train_model(metadata={})\n",
    "kerasModel.print_indexes_info()\n",
    "\n",
    "# 7. Comparación con los resultados anteriores\n",
    "indexes[\"Tensorflow/Keras\"] = list(kerasModel.indexes.get_indexes_dictionary().values())\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Resultados:**\n",
    "- Si comparamos MLPClassifier con las tareas anteriores podemos ver que los valores no son optimos para resolver esta clasificación, una precisión global de 0.73 es mala comparado con otros métodos que tienen una precisión cercana al 100%\n",
    "- La comparación de Keras con los métodos anteriores es muy buena, sin embargo no es la mejor, Random Forest es un mejor modelo a usar por su precisión y menor uso de recursos computacionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               media     varianza  desviacion.estandar  entropia  asimetria  \\\n",
      "imagen                                                                        \n",
      "Image1     23.448517  2538.985627            50.388348  0.651174   1.984202   \n",
      "Image2      4.398331   834.853030            28.893823  0.953532   6.495203   \n",
      "Image3      3.244263   642.059166            25.338886  0.966065   7.772860   \n",
      "Image4      8.511353  1126.214187            33.559115  0.868765   3.763142   \n",
      "Image5     21.000793  2235.316978            47.279139  0.684724   1.936029   \n",
      "...              ...          ...                  ...       ...        ...   \n",
      "Image1640   0.199158    26.491880             5.147026  0.996341  25.826301   \n",
      "Image1641   6.885025   802.478515            28.328052  0.878419   3.939967   \n",
      "Image1642   1.828186   230.107684            15.169301  0.966424   8.218790   \n",
      "Image1643   0.061630     8.029570             2.833650  0.998740  45.985085   \n",
      "Image1644   0.718506    91.460572             9.563502  0.986739  13.268497   \n",
      "\n",
      "              kurtosis   contraste   energia       asm  homogeneidad  \\\n",
      "imagen                                                                 \n",
      "Image1        5.421042  181.467713  0.781557  0.610831      0.847033   \n",
      "Image2       43.349355   76.745886  0.972770  0.946281      0.980762   \n",
      "Image3       61.756034   81.752406  0.980161  0.960715      0.985066   \n",
      "Image4       15.107579  362.291213  0.921786  0.849690      0.949295   \n",
      "Image5        4.722343  312.439226  0.804184  0.646711      0.880301   \n",
      "...                ...         ...       ...       ...           ...   \n",
      "Image1640   668.181974   14.797350  0.997873  0.995751      0.998476   \n",
      "Image1641    16.456794  266.135425  0.927687  0.860602      0.951086   \n",
      "Image1642    68.539071  105.172699  0.980371  0.961128      0.985590   \n",
      "Image1643  2116.600001    6.431276  0.999268  0.998536      0.999401   \n",
      "Image1644   177.139371   42.023257  0.992277  0.984614      0.994537   \n",
      "\n",
      "           disiminitud  correlacion        psnr      ssim       mse        dc  \\\n",
      "imagen                                                                          \n",
      "Image1        2.765411     0.968576   97.974630  0.777011  0.171163  0.303989   \n",
      "Image2        0.548605     0.959751  110.346597  0.977953  0.009913  0.839019   \n",
      "Image3        0.540411     0.944259  112.266298  0.985362  0.006372  0.849775   \n",
      "Image4        2.765725     0.859027  101.955792  0.881015  0.068437  0.000000   \n",
      "Image5        3.006660     0.938572   97.639870  0.766308  0.184878  0.000000   \n",
      "...                ...          ...         ...       ...       ...       ...   \n",
      "Image1640     0.113842     0.755553   75.822768  0.995798  0.001701  0.000000   \n",
      "Image1641     2.303173     0.854682   60.126401  0.886831  0.063160  0.000000   \n",
      "Image1642     0.863250     0.799919   66.013000  0.964771  0.016285  0.000000   \n",
      "Image1643     0.050628     0.649484   80.821412  0.998316  0.000538  0.000000   \n",
      "Image1644     0.341771     0.798902   70.076550  0.985988  0.006389  0.000000   \n",
      "\n",
      "          tipo  \n",
      "imagen          \n",
      "Image1       1  \n",
      "Image2       1  \n",
      "Image3       1  \n",
      "Image4       0  \n",
      "Image5       0  \n",
      "...        ...  \n",
      "Image1640    0  \n",
      "Image1641    0  \n",
      "Image1642    0  \n",
      "Image1643    0  \n",
      "Image1644    0  \n",
      "\n",
      "[1275 rows x 17 columns]\n",
      "\n",
      "Variables Predictoras:\n",
      "\n",
      "            media     varianza  desviacion.estandar  entropia  asimetria  \\\n",
      "imagen                                                                     \n",
      "Image1  23.448517  2538.985627            50.388348  0.651174   1.984202   \n",
      "Image2   4.398331   834.853030            28.893823  0.953532   6.495203   \n",
      "Image3   3.244263   642.059166            25.338886  0.966065   7.772860   \n",
      "Image4   8.511353  1126.214187            33.559115  0.868765   3.763142   \n",
      "Image5  21.000793  2235.316978            47.279139  0.684724   1.936029   \n",
      "\n",
      "         kurtosis   contraste   energia       asm  homogeneidad  disiminitud  \\\n",
      "imagen                                                                         \n",
      "Image1   5.421042  181.467713  0.781557  0.610831      0.847033     2.765411   \n",
      "Image2  43.349355   76.745886  0.972770  0.946281      0.980762     0.548605   \n",
      "Image3  61.756034   81.752406  0.980161  0.960715      0.985066     0.540411   \n",
      "Image4  15.107579  362.291213  0.921786  0.849690      0.949295     2.765725   \n",
      "Image5   4.722343  312.439226  0.804184  0.646711      0.880301     3.006660   \n",
      "\n",
      "        correlacion        psnr      ssim       mse        dc  \n",
      "imagen                                                         \n",
      "Image1     0.968576   97.974630  0.777011  0.171163  0.303989  \n",
      "Image2     0.959751  110.346597  0.977953  0.009913  0.839019  \n",
      "Image3     0.944259  112.266298  0.985362  0.006372  0.849775  \n",
      "Image4     0.859027  101.955792  0.881015  0.068437  0.000000  \n",
      "Image5     0.938572   97.639870  0.766308  0.184878  0.000000  \n",
      "\n",
      "Variable a Predecir:\n",
      "\n",
      "       tipo\n",
      "imagen     \n",
      "Image1    1\n",
      "Image2    1\n",
      "Image3    1\n",
      "Image4    0\n",
      "Image5    0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsalazar/Development/learning/machine_learning/promidat/src/methodology/supervised/calcs/IndexesCalculator.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.__assertiveness_by_category = pd.DataFrame(self.__matrix.diagonal() / np.sum(self.__matrix, axis = 0)).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precisión Global: 0.9138381201044387\n",
      "\n",
      "Precisión por Categoría:\n",
      "\n",
      "     0    1\n",
      "0  0.0  1.0\n",
      "\n",
      "Variables Predictoras:\n",
      "\n",
      "            media     varianza  desviacion.estandar  entropia  asimetria  \\\n",
      "imagen                                                                     \n",
      "Image1  23.448517  2538.985627            50.388348  0.651174   1.984202   \n",
      "Image2   4.398331   834.853030            28.893823  0.953532   6.495203   \n",
      "Image3   3.244263   642.059166            25.338886  0.966065   7.772860   \n",
      "Image4   8.511353  1126.214187            33.559115  0.868765   3.763142   \n",
      "Image5  21.000793  2235.316978            47.279139  0.684724   1.936029   \n",
      "\n",
      "         kurtosis   contraste   energia       asm  homogeneidad  disiminitud  \\\n",
      "imagen                                                                         \n",
      "Image1   5.421042  181.467713  0.781557  0.610831      0.847033     2.765411   \n",
      "Image2  43.349355   76.745886  0.972770  0.946281      0.980762     0.548605   \n",
      "Image3  61.756034   81.752406  0.980161  0.960715      0.985066     0.540411   \n",
      "Image4  15.107579  362.291213  0.921786  0.849690      0.949295     2.765725   \n",
      "Image5   4.722343  312.439226  0.804184  0.646711      0.880301     3.006660   \n",
      "\n",
      "        correlacion        psnr      ssim       mse        dc  \n",
      "imagen                                                         \n",
      "Image1     0.968576   97.974630  0.777011  0.171163  0.303989  \n",
      "Image2     0.959751  110.346597  0.977953  0.009913  0.839019  \n",
      "Image3     0.944259  112.266298  0.985362  0.006372  0.849775  \n",
      "Image4     0.859027  101.955792  0.881015  0.068437  0.000000  \n",
      "Image5     0.938572   97.639870  0.766308  0.184878  0.000000  \n",
      "\n",
      "Variable a Predecir:\n",
      "\n",
      "        0\n",
      "imagen   \n",
      "Image1  0\n",
      "Image2  0\n",
      "Image3  0\n",
      "Image4  1\n",
      "Image5  1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 451\n",
      "Trainable params: 451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "12/12 [==============================] - 0s 622us/step - loss: 0.1136 - accuracy: 0.9556\n",
      "\n",
      "Precisión Global: 0.9556135770234987\n",
      "\n",
      "Precisión por Categoría:\n",
      "\n",
      "          0         1\n",
      "0  0.954286  0.969697\n",
      "Matriz de Comparación\n",
      "                  K-Neighbors  Random Forest  ADA Boosting  XG Boosting  \\\n",
      "Precisión Global     0.906005       0.992167      0.989556     0.986945   \n",
      "Error Global         0.093995       0.007833      0.010444     0.013055   \n",
      "Precisión 0          0.000000       1.000000      0.969697     0.939394   \n",
      "Precisión 1          0.991429       0.991429      0.991429     0.991429   \n",
      "Falso Positivo 0     1.000000       0.000000      0.030303     0.060606   \n",
      "Falso Positivo 1     0.008571       0.008571      0.008571     0.008571   \n",
      "Asertividad 0        1.000000       0.000000      0.030303     0.060606   \n",
      "Asertividad 1        0.008571       0.008571      0.008571     0.008571   \n",
      "\n",
      "                  SVM Model  Decision Tree  Multi Layer Perceptron  \\\n",
      "Precisión Global   0.913838       0.984334                0.913838   \n",
      "Error Global       0.086162       0.015666                0.086162   \n",
      "Precisión 0        0.000000       0.909091                0.000000   \n",
      "Precisión 1        1.000000       0.991429                1.000000   \n",
      "Falso Positivo 0   1.000000       0.090909                1.000000   \n",
      "Falso Positivo 1   0.000000       0.008571                0.000000   \n",
      "Asertividad 0      1.000000       0.090909                1.000000   \n",
      "Asertividad 1      0.000000       0.008571                0.000000   \n",
      "\n",
      "                  Tensorflow/Keras  \n",
      "Precisión Global          0.955614  \n",
      "Error Global              0.044386  \n",
      "Precisión 0               0.954286  \n",
      "Precisión 1               0.969697  \n",
      "Falso Positivo 0          0.045714  \n",
      "Falso Positivo 1          0.030303  \n",
      "Asertividad 0             0.045714  \n",
      "Asertividad 1             0.030303  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsalazar/Development/learning/machine_learning/promidat/src/methodology/supervised/calcs/IndexesCalculator.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.__assertiveness_by_category = pd.DataFrame(self.__matrix.diagonal() / np.sum(self.__matrix, axis = 0)).T\n"
     ]
    }
   ],
   "source": [
    "from utils.DataFrameUtils import DataFrameUtils\n",
    "from methodology.supervised.classificators.MLPerceptronModel import MLPerceptronModel\n",
    "from methodology.supervised.classificators.KNeighborsModel import KNeighborsModel\n",
    "from methodology.supervised.classificators.ADABoostingModel import ADABoostingModel\n",
    "from methodology.supervised.classificators.XGBoostingModel import XGBoostingModel\n",
    "from methodology.supervised.classificators.RandomForestModel import RandomForestModel\n",
    "from methodology.supervised.classificators.SVMModel import SVMModel\n",
    "from methodology.supervised.classificators.DecisionTreeModel import DecisionTreeModel\n",
    "from methodology.supervised.classificators.KerasModel import KerasModel\n",
    "\n",
    "\n",
    "tumores_path = \"/Users/rsalazar/Development/learning/machine_learning/promidat/src/data/tumores.csv\"\n",
    "data_tumores = DataFrameUtils.read_cvs(tumores_path, delimiter=\",\", decimal=\".\", index_col=0)\n",
    "data_tumores['tipo'] = data_tumores['tipo'].astype('category')\n",
    "print(data_tumores)\n",
    "\n",
    "# 1. Utilizando el modelo MLPClassifier\n",
    "mlpModel = MLPerceptronModel(data_tumores)\n",
    "mlpModel.build_model(variable_predict=\"tipo\", train_size=0.7)\n",
    "mlpModel.print_testing_info()\n",
    "mlpModel.train_model(metadata = {\"hidden_layer_sizes\": (1000,500)})\n",
    "mlpModel.print_indexes_info()\n",
    "\n",
    "# 1. Utilizando el modelo Tensorflow/Keras\n",
    "\n",
    "kerasModel = KerasModel(data_tumores)\n",
    "kerasModel.build_model(variable_predict = \"tipo\", train_size = 0.7)\n",
    "kerasModel.print_testing_info()\n",
    "kerasModel.train_model(metadata={})\n",
    "kerasModel.print_indexes_info()\n",
    "\n",
    "# 2.  Generación de los modelos anteriores\n",
    "\n",
    "# K-Neighbors\n",
    "kNeighborsModel = KNeighborsModel(data_tumores)\n",
    "kNeighborsModel.build_model(variable_predict = \"tipo\", train_size = 0.7)\n",
    "kNeighborsModel.train_model(metadata = {})\n",
    "kNeighborsModel.calculate_indexes()\n",
    "\n",
    "# Random Forest\n",
    "randomForestModel = RandomForestModel(data_tumores)\n",
    "randomForestModel.build_model(variable_predict = \"tipo\", train_size = 0.7)\n",
    "randomForestModel.train_model(metadata = {})\n",
    "randomForestModel.calculate_indexes()\n",
    "\n",
    "# ADA Boosting\n",
    "adaBoostingModel = ADABoostingModel(data_tumores)\n",
    "adaBoostingModel.build_model(variable_predict = \"tipo\", train_size = 0.7)\n",
    "adaBoostingModel.train_model(metadata = {})\n",
    "adaBoostingModel.calculate_indexes()\n",
    "\n",
    "# ADA Boosting\n",
    "xgBoostingModel = XGBoostingModel(data_tumores)\n",
    "xgBoostingModel.build_model(variable_predict = \"tipo\", train_size = 0.7)\n",
    "xgBoostingModel.train_model(metadata = {})\n",
    "xgBoostingModel.calculate_indexes()\n",
    "\n",
    "# Decision Tree\n",
    "decisionTreeModel = DecisionTreeModel(data_tumores)\n",
    "decisionTreeModel.build_model(variable_predict = \"tipo\", train_size = 0.7)\n",
    "decisionTreeModel.train_model(metadata = {})\n",
    "decisionTreeModel.calculate_indexes()\n",
    "\n",
    "# Support Vector Machines\n",
    "svmModel = SVMModel(data_tumores)\n",
    "svmModel.build_model(variable_predict = \"tipo\", train_size = 0.7)\n",
    "svmModel.train_model(metadata = {})\n",
    "svmModel.calculate_indexes()\n",
    "\n",
    "# 3. Generación de cuadro comparativo\n",
    "print(\"Matriz de Comparación\")\n",
    "indexes = DataFrameUtils.create_dataframe_from_dict(\n",
    "    [\n",
    "        kNeighborsModel.indexes.get_indexes_dictionary(),\n",
    "        randomForestModel.indexes.get_indexes_dictionary(),\n",
    "        adaBoostingModel.indexes.get_indexes_dictionary(),\n",
    "        xgBoostingModel.indexes.get_indexes_dictionary(),\n",
    "        svmModel.indexes.get_indexes_dictionary(),\n",
    "        decisionTreeModel.indexes.get_indexes_dictionary(),\n",
    "        mlpModel.indexes.get_indexes_dictionary(),\n",
    "        kerasModel.indexes.get_indexes_dictionary()\n",
    "    ], columns = [\n",
    "        \"K-Neighbors\",\n",
    "        \"Random Forest\", \n",
    "        \"ADA Boosting\", \n",
    "        \"XG Boosting\",\n",
    "        \"SVM Model\",\n",
    "        \"Decision Tree\",\n",
    "        \"Multi Layer Perceptron\",\n",
    "        \"Tensorflow/Keras\"])\n",
    "print(indexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Resultados:**\n",
    "- En este problema de clasificación el modelo MLP tiene mejores resultados que dos métodos, sin embargo no es el más optimo, se consideraría otro metodo que no requiera un alto poder computacional para resolver este problema\n",
    "- Keras no muestra los mejores resultados para esta predicción, al igual que en el ejemplo anteriore, se utilizaría Random Forest debido a sus mejores resultados y menor uso de recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  y\n",
      "0   0   0  1\n",
      "1   1   0  1\n",
      "2   0   1  1\n",
      "3   1   1  0\n",
      "Testing: w1 = -3, w2 = 2, t = -2\n",
      "Testing: w1 = 3, w2 = -1, t = 4\n",
      "Testing: w1 = 3, w2 = 0, t = 4\n",
      "Testing: w1 = 3, w2 = 3, t = 3\n",
      "Testing: w1 = -3, w2 = -1, t = 1\n",
      "Testing: w1 = -1, w2 = -1, t = -2\n",
      "Testing: w1 = 3, w2 = -4, t = 0\n",
      "Testing: w1 = 3, w2 = 1, t = -2\n",
      "Testing: w1 = 1, w2 = 3, t = 0\n",
      "Testing: w1 = 4, w2 = 2, t = -1\n",
      "Testing: w1 = 5, w2 = -5, t = 2\n",
      "Testing: w1 = -3, w2 = 5, t = 4\n",
      "Testing: w1 = -3, w2 = -5, t = -1\n",
      "Testing: w1 = -5, w2 = 3, t = 3\n",
      "Testing: w1 = 0, w2 = -3, t = -2\n",
      "Testing: w1 = -1, w2 = -1, t = -5\n",
      "Testing: w1 = 1, w2 = -1, t = 5\n",
      "Testing: w1 = -3, w2 = -4, t = 1\n",
      "Testing: w1 = -3, w2 = -1, t = 2\n",
      "Testing: w1 = 5, w2 = -3, t = -3\n",
      "Testing: w1 = 3, w2 = -3, t = 4\n",
      "Testing: w1 = -4, w2 = -1, t = -3\n",
      "Testing: w1 = -5, w2 = 5, t = 1\n",
      "Testing: w1 = 4, w2 = 3, t = 3\n",
      "Testing: w1 = 2, w2 = -1, t = 3\n",
      "Testing: w1 = -1, w2 = -1, t = 5\n",
      "Testing: w1 = 1, w2 = 0, t = 4\n",
      "Testing: w1 = 3, w2 = 5, t = 4\n",
      "Testing: w1 = 0, w2 = 1, t = 1\n",
      "Testing: w1 = 5, w2 = 0, t = 5\n",
      "Testing: w1 = -3, w2 = -1, t = 0\n",
      "Testing: w1 = -5, w2 = -4, t = -3\n",
      "Testing: w1 = 4, w2 = -1, t = -3\n",
      "Testing: w1 = -3, w2 = 5, t = 5\n",
      "Testing: w1 = 0, w2 = -4, t = -5\n",
      "Testing: w1 = -5, w2 = 3, t = 2\n",
      "Testing: w1 = 5, w2 = -1, t = -4\n",
      "Testing: w1 = 3, w2 = 0, t = -2\n",
      "Testing: w1 = 0, w2 = 5, t = 0\n",
      "Testing: w1 = 1, w2 = -1, t = 1\n",
      "Testing: w1 = 4, w2 = -3, t = 0\n",
      "Testing: w1 = 4, w2 = -3, t = -1\n",
      "Testing: w1 = -3, w2 = 3, t = 5\n",
      "Testing: w1 = 0, w2 = -3, t = -1\n",
      "Testing: w1 = 4, w2 = -4, t = -3\n",
      "Testing: w1 = 0, w2 = -4, t = -4\n",
      "Testing: w1 = 3, w2 = -1, t = 4\n",
      "Testing: w1 = 5, w2 = -1, t = 4\n",
      "Testing: w1 = 2, w2 = -2, t = 3\n",
      "Testing: w1 = -5, w2 = -4, t = 2\n",
      "Testing: w1 = 0, w2 = 1, t = -3\n",
      "Testing: w1 = -3, w2 = 1, t = -2\n",
      "Testing: w1 = -3, w2 = 5, t = 4\n",
      "Testing: w1 = 5, w2 = 5, t = 4\n",
      "Testing: w1 = -5, w2 = -1, t = -3\n",
      "Testing: w1 = 5, w2 = 1, t = -3\n",
      "Testing: w1 = -4, w2 = -5, t = -3\n",
      "Testing: w1 = -3, w2 = -4, t = 1\n",
      "Testing: w1 = 0, w2 = 1, t = 1\n",
      "Testing: w1 = 2, w2 = 4, t = -4\n",
      "Testing: w1 = -1, w2 = 3, t = 2\n",
      "Testing: w1 = -2, w2 = -3, t = 0\n",
      "Testing: w1 = 4, w2 = -4, t = 3\n",
      "Testing: w1 = -2, w2 = -5, t = 1\n",
      "Testing: w1 = -2, w2 = -3, t = 1\n",
      "Testing: w1 = 0, w2 = 3, t = -5\n",
      "Testing: w1 = 5, w2 = 2, t = -2\n",
      "Testing: w1 = 4, w2 = -2, t = 1\n",
      "Testing: w1 = 5, w2 = 4, t = 4\n",
      "Testing: w1 = 1, w2 = -1, t = -2\n",
      "Testing: w1 = 3, w2 = -3, t = -1\n",
      "Testing: w1 = 3, w2 = 5, t = 1\n",
      "Testing: w1 = 4, w2 = 0, t = 3\n",
      "Testing: w1 = 3, w2 = 4, t = -4\n",
      "Testing: w1 = -1, w2 = -3, t = 2\n",
      "Testing: w1 = 3, w2 = -3, t = 3\n",
      "Testing: w1 = 4, w2 = 0, t = 3\n",
      "Testing: w1 = 3, w2 = -4, t = 0\n",
      "Testing: w1 = 5, w2 = 0, t = -3\n",
      "Testing: w1 = 3, w2 = 2, t = -2\n",
      "Testing: w1 = 3, w2 = 3, t = 5\n",
      "Testing: w1 = -2, w2 = 1, t = 1\n",
      "Testing: w1 = 0, w2 = -2, t = 3\n",
      "Testing: w1 = -1, w2 = -5, t = 4\n",
      "Testing: w1 = 0, w2 = -5, t = 4\n",
      "Testing: w1 = 1, w2 = 5, t = 4\n",
      "Testing: w1 = 0, w2 = -3, t = -2\n",
      "Testing: w1 = 3, w2 = 5, t = 5\n",
      "Testing: w1 = -3, w2 = 0, t = -5\n",
      "Testing: w1 = -2, w2 = 3, t = -3\n",
      "Testing: w1 = 1, w2 = -3, t = -2\n",
      "Testing: w1 = -2, w2 = 2, t = -4\n",
      "Testing: w1 = -5, w2 = -2, t = 5\n",
      "Testing: w1 = -1, w2 = 0, t = 1\n",
      "Testing: w1 = 5, w2 = -5, t = -1\n",
      "Testing: w1 = -4, w2 = -4, t = 5\n",
      "Testing: w1 = 1, w2 = -1, t = -5\n",
      "Testing: w1 = 2, w2 = 0, t = 5\n",
      "Testing: w1 = 5, w2 = -5, t = 4\n",
      "Testing: w1 = 0, w2 = -2, t = -3\n",
      "Testing: w1 = -5, w2 = 5, t = -5\n",
      "Testing: w1 = -2, w2 = -5, t = -4\n",
      "Testing: w1 = 4, w2 = 4, t = -1\n",
      "Testing: w1 = 3, w2 = -4, t = -5\n",
      "Testing: w1 = 3, w2 = -3, t = 0\n",
      "Testing: w1 = 1, w2 = 3, t = -2\n",
      "Testing: w1 = 1, w2 = -5, t = -4\n",
      "Testing: w1 = 4, w2 = 2, t = -2\n",
      "Testing: w1 = 1, w2 = -5, t = -2\n",
      "Testing: w1 = -2, w2 = 5, t = 4\n",
      "Testing: w1 = -2, w2 = 3, t = 5\n",
      "Testing: w1 = -5, w2 = -1, t = -1\n",
      "Testing: w1 = 4, w2 = 2, t = 3\n",
      "Testing: w1 = -4, w2 = 5, t = -5\n",
      "Testing: w1 = 1, w2 = -4, t = 3\n",
      "Testing: w1 = 2, w2 = -3, t = 4\n",
      "Testing: w1 = 5, w2 = -4, t = -4\n",
      "Testing: w1 = 3, w2 = 1, t = -4\n",
      "Testing: w1 = -1, w2 = -4, t = 1\n",
      "Testing: w1 = -3, w2 = -1, t = -4\n",
      "Testing: w1 = 5, w2 = 0, t = 3\n",
      "Testing: w1 = 4, w2 = -4, t = 5\n",
      "Testing: w1 = -3, w2 = 3, t = 4\n",
      "Testing: w1 = -4, w2 = 4, t = 4\n",
      "Testing: w1 = 2, w2 = -2, t = 3\n",
      "Testing: w1 = -5, w2 = 4, t = 3\n",
      "Testing: w1 = 1, w2 = -4, t = 3\n",
      "Testing: w1 = -1, w2 = -2, t = -1\n",
      "Testing: w1 = 5, w2 = 1, t = 4\n",
      "Testing: w1 = -5, w2 = -3, t = 5\n",
      "Testing: w1 = 5, w2 = -2, t = 0\n",
      "Testing: w1 = 2, w2 = -2, t = -3\n",
      "Testing: w1 = 1, w2 = 5, t = -5\n",
      "Testing: w1 = 5, w2 = -2, t = 3\n",
      "Testing: w1 = -4, w2 = 0, t = -1\n",
      "Testing: w1 = -1, w2 = 1, t = -3\n",
      "Testing: w1 = 0, w2 = -4, t = -3\n",
      "Testing: w1 = -3, w2 = -3, t = 3\n",
      "Testing: w1 = 0, w2 = 5, t = -4\n",
      "Testing: w1 = -5, w2 = 3, t = -4\n",
      "Testing: w1 = -5, w2 = 1, t = 2\n",
      "Testing: w1 = 0, w2 = 2, t = -5\n",
      "Testing: w1 = 1, w2 = 3, t = -5\n",
      "Testing: w1 = -4, w2 = -4, t = 4\n",
      "Testing: w1 = -4, w2 = -3, t = 2\n",
      "Testing: w1 = -4, w2 = -2, t = 4\n",
      "Testing: w1 = 2, w2 = -4, t = 4\n",
      "Testing: w1 = -3, w2 = 4, t = 4\n",
      "Testing: w1 = 4, w2 = 1, t = 2\n",
      "Testing: w1 = -1, w2 = 3, t = -2\n",
      "Testing: w1 = 4, w2 = 5, t = 1\n",
      "Testing: w1 = -1, w2 = 3, t = 1\n",
      "Testing: w1 = 0, w2 = -4, t = 5\n",
      "Testing: w1 = -5, w2 = -2, t = -4\n",
      "Testing: w1 = -3, w2 = 3, t = -4\n",
      "Testing: w1 = 5, w2 = 0, t = 2\n",
      "Testing: w1 = -1, w2 = 2, t = -5\n",
      "Testing: w1 = 4, w2 = -4, t = 3\n",
      "Testing: w1 = -2, w2 = 4, t = 5\n",
      "Testing: w1 = 5, w2 = 4, t = 4\n",
      "Testing: w1 = 2, w2 = 2, t = 1\n",
      "Testing: w1 = 3, w2 = 3, t = 5\n",
      "Testing: w1 = 1, w2 = -1, t = -2\n",
      "Testing: w1 = -1, w2 = 1, t = 3\n",
      "Testing: w1 = 4, w2 = -3, t = -2\n",
      "Testing: w1 = 3, w2 = 2, t = 1\n",
      "Testing: w1 = -4, w2 = 4, t = 4\n",
      "Testing: w1 = -2, w2 = 3, t = 0\n",
      "Testing: w1 = -2, w2 = -5, t = 2\n",
      "Testing: w1 = 0, w2 = 2, t = 0\n",
      "Testing: w1 = -5, w2 = -5, t = 3\n",
      "Testing: w1 = -1, w2 = 1, t = -2\n",
      "Testing: w1 = 0, w2 = 4, t = -5\n",
      "Testing: w1 = -5, w2 = 2, t = -4\n",
      "Testing: w1 = -5, w2 = -3, t = -1\n",
      "Testing: w1 = 1, w2 = 2, t = -1\n",
      "Testing: w1 = 3, w2 = -1, t = -1\n",
      "Testing: w1 = 3, w2 = -4, t = -4\n",
      "Testing: w1 = 4, w2 = -4, t = -5\n",
      "Testing: w1 = -1, w2 = 5, t = -2\n",
      "Testing: w1 = -3, w2 = 4, t = 4\n",
      "Testing: w1 = 2, w2 = -4, t = -5\n",
      "Testing: w1 = 1, w2 = 3, t = 0\n",
      "Testing: w1 = -3, w2 = -4, t = -2\n",
      "Testing: w1 = -3, w2 = -1, t = 5\n",
      "Testing: w1 = 1, w2 = 0, t = 0\n",
      "Testing: w1 = -5, w2 = -4, t = -4\n",
      "Testing: w1 = -4, w2 = -4, t = -2\n",
      "Testing: w1 = 3, w2 = -3, t = 3\n",
      "Testing: w1 = -3, w2 = -3, t = 3\n",
      "Testing: w1 = -1, w2 = 0, t = 0\n",
      "Testing: w1 = 0, w2 = 2, t = -2\n",
      "Testing: w1 = 5, w2 = 2, t = 5\n",
      "Testing: w1 = -5, w2 = -4, t = -4\n",
      "Testing: w1 = -1, w2 = 3, t = 1\n",
      "Testing: w1 = -2, w2 = -3, t = 5\n",
      "Testing: w1 = 0, w2 = 1, t = -1\n",
      "Testing: w1 = -1, w2 = 2, t = -3\n",
      "Testing: w1 = -2, w2 = -3, t = 4\n",
      "Testing: w1 = -1, w2 = -3, t = 3\n",
      "Testing: w1 = -4, w2 = -3, t = -1\n",
      "Testing: w1 = 1, w2 = -2, t = 1\n",
      "Testing: w1 = 3, w2 = 3, t = 3\n",
      "Testing: w1 = 2, w2 = -3, t = -4\n",
      "Testing: w1 = -2, w2 = 1, t = 0\n",
      "Testing: w1 = 1, w2 = -4, t = -1\n",
      "Testing: w1 = 2, w2 = -2, t = 2\n",
      "Testing: w1 = -3, w2 = -2, t = -4\n",
      "Success...\n",
      "\n",
      "Required values: \n",
      "\tw1 = -3\n",
      "\tw2 = -2\n",
      "\tt  = -4\n"
     ]
    }
   ],
   "source": [
    "from utils.DataFrameUtils import DataFrameUtils\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "def get_random_numbers():\n",
    "    random.seed()\n",
    "    w1 = random.randint(-5, 5)\n",
    "    w2 = random.randint(-5, 5)\n",
    "    t = random.randint(-5, 5) \n",
    "    return (w1, w2, t)\n",
    "\n",
    "def verify_values(array1, array2):\n",
    "    return (array1 == array2).all()\n",
    "\n",
    "def sigmoidea(x1, x2, w1, w2, t):\n",
    "    percept = 1 / (1 + math.exp(-1 * (x1*w1 + x2*w2 - t)))\n",
    "    return 1 if percept >= 0.5 else 0\n",
    "\n",
    "data = DataFrameUtils.create_dataframe_from_dict(\n",
    "    {\n",
    "        \"x1\": [0, 1, 0, 1],\n",
    "        \"x2\": [0, 0, 1, 1],\n",
    "        \"y\":  [1, 1, 1, 0]\n",
    "    }\n",
    ")\n",
    "print(data)\n",
    "\n",
    "while True:\n",
    "    w1, w2, t = get_random_numbers()\n",
    "    col = data.apply(lambda row: sigmoidea(row[\"x1\"], row[\"x2\"], w1, w2, t), axis=1)\n",
    "    print(f\"Testing: w1 = {w1}, w2 = {w2}, t = {t}\")\n",
    "    if verify_values(data[\"y\"], col):\n",
    "        print(\"Success...\")\n",
    "        break\n",
    "\n",
    "print(\"\\nRequired values: \")\n",
    "print(f\"\\tw1 = {w1}\\n\\tw2 = {w2}\\n\\tt  = {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      w1   w2   w3    T\n",
      "0    1.0 -1.0 -1.0  0.0\n",
      "1    1.0 -0.9 -1.0  0.0\n",
      "2    1.0 -0.8 -1.0  0.0\n",
      "3    1.0 -0.7 -1.0  0.0\n",
      "4    1.0 -0.6 -1.0  0.0\n",
      "..   ...  ...  ...  ...\n",
      "710  1.0 -0.2 -0.2  0.8\n",
      "711  1.0 -0.1 -0.2  0.8\n",
      "712  1.0 -0.2 -0.1  0.8\n",
      "713  0.9 -0.1 -0.1  0.8\n",
      "714  1.0 -0.1 -0.1  0.9\n",
      "\n",
      "[715 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from utils.DataFrameUtils import DataFrameUtils\n",
    "\n",
    "data = DataFrameUtils.create_dataframe_from_dict(\n",
    "    {\n",
    "        \"x1\": [1, 1, 1, 1],\n",
    "        \"x2\": [0, 0, 1, 1],\n",
    "        \"x3\": [0, 1, 0, 1],\n",
    "        \"z\":  [1, 1, 1, 0]\n",
    "    }\n",
    ")\n",
    "\n",
    "def verify_values(array1, array2):\n",
    "    return (array1 == array2).all()\n",
    "\n",
    "def perceptron(x1, x2, x3, w1, w2, w3, t):\n",
    "    return (x1 * w1 + x2 * w2 + x3 * w3 - t)\n",
    "\n",
    "def tangente_hiperbolica(x1, x2, x3, w1, w2, w3, t):\n",
    "    val = (2 / (1 + math.exp(-2 * perceptron(x1, x2, x3, w1, w2, w3, t)))) - 1\n",
    "    return 1 if val >= 0 else 0\n",
    "\n",
    "weights = [x * 0.1 for x in range(-10, 11)]\n",
    "thetas = [x * 0.1 for x in range(0, 11)]\n",
    "\n",
    "success_values = list()\n",
    "\n",
    "for t in thetas:\n",
    "    for w3 in weights:\n",
    "        for w2 in weights:\n",
    "            for w1 in weights:\n",
    "                tangente = data.apply(lambda row: tangente_hiperbolica(row[\"x1\"], row[\"x2\"], row[\"x3\"], w1, w2, w3, t), axis=1)\n",
    "                if verify_values(tangente, data[\"z\"]):\n",
    "                    success_values.append([w1, w2, w3, t])\n",
    "\n",
    "print(DataFrameUtils.create_dataframe(success_values, columns=[\"w1\", \"w2\", \"w3\", \"T\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Resulados:**\n",
    "- Al parecer existen muchas posibles soluciones para este problema, lo que nos lleva a pensar a que se debería utilizar mejores parámetros para poder resolver esta red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('promidat_env': venv)",
   "language": "python",
   "name": "python37364bitpromidatenvvenvc3e7e1ef11174b41ae8efad0d6e5a79c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
